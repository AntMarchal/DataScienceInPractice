{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group Members\n",
    "* Bellahsene Allan\n",
    "* Brodard Lionel\n",
    "* Marchal Antoine\n",
    "* Meylan Valentin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [1. Introduction](#Introduction)\n",
    "* [2. Exploratory Data Analysis and Data Preparation](#ExploratoryDataAnalysis)\n",
    "* [3. Prediction](#Prediction)\n",
    "    * [3.1 Models](#Models)\n",
    "    * [3.2 Model evaluation](#Model_evaluation)\n",
    "    * [3.3 Model improvement](#Model_improvement)\n",
    "* [3. Conclusion](#Conclusion)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction <a class=\"anchor\" id=\"Introduction\"></a>\n",
    "\n",
    "The objective is to predict the customer churn of the telecom company."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Exploratory Data Analysis and Data Preparation <a class=\"anchor\" id=\"ExploratoryDataAnalysis\"></a>\n",
    "\n",
    "The data are preprocess as described in assignement 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Prediction <a class=\"anchor\" id=\"Prediction\"></a>\n",
    "Given that what we try to predict is a categorical variable with two classes: 'Churn' or 'No Churn', we have used classification models descibed in the section [Models](#Models). They have been trained on a train set and test on a test set (we used a 0.75/0.25 split respectively for the train and test data set). In oder to avoid overfitting we used a L2 regularization, the hyperparameter were fixed using a 5-fold cross-validation. The metrics used for the fitting of the hyperparameter and the model selection are discribed in the section [Model evaluation](#Model_evaluation). Some improvement suggestion were then devellopped in section [Model improvement](#Model_improvement)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.1 Models** <a class=\"anchor\" id=\"Models\"></a>\n",
    "\n",
    "We tested two different classification models:\n",
    "- **Logistic Regression**: Logistic regression allows one to transform the predictions that take values in $(-\\infty, +\\infty)$ into a true probability by applying the so-called logistic function $\\sigma(z) = \\frac{e^z}{1+e^z}$.\n",
    "The label $y$ to predict is Churn, while all other variables, the features, are denoted by the matrix $x$. We have:\n",
    "$p(y=1|x,w) = \\sigma(x^T w), p(y=0|x,w) = 1 - \\sigma(x^T w)$, where $w$ is the weight matrix to optimize.\n",
    "- **Support Vector Classification**:  Support Vector Machine is a way to classify data by choosing a hyperplane. The goal is to maximize the distance between the hyperplane to the nearest data point of each class.\n",
    "\n",
    "In both case a L2 regularization term of the form $\\lambda |w|^2$ were $\\lambda$ is a positive hyperparameter, was added to the respective objective functions in order to avoid overfitting. Indeed this parameter penalize large (in term of L2 norm) vector $w$. These hyperparameter were fixed using 5-fold cross-validation. They were chosen to maximize their test score according to the metrics defined below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.2 Model evaluation** <a class=\"anchor\" id=\"Model_evaluation\"></a>\n",
    "\n",
    "We need to defined some classification metrics with respect to which we could compare models with different hyperparameter. In the end the best hyperparameter is fixed through cross-validation as the hyperparameter that maximized a given metric for a given model.\n",
    "We investigated four different metric:\n",
    "* Accuracy = $\\frac{True Positive+True Negative}{True Positive + True Negative + False Positive + False Negative}$\n",
    "* Precision = $\\frac{TP}{TP + FP}$\n",
    "* Recall = $\\frac{TP}{TP+FN}$\n",
    "* F1 = $2 \\times \\frac{Precision \\times Recall}{Precision + Recall}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.3 Model improvement** <a class=\"anchor\" id=\"Model_improvement\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We tried to different things in order to improve our prediction:\n",
    "- **PCA**: We used a principal component annalysis in order to eliminate the residual colinearity that subsisted in our data set. We kept all the component as our goal was not to perform a dimensionality reduction but simply to obtain orthogonal components.\n",
    "- **Standardization**: We standardized the data by removing the mean and dividing by the volatility of each feature.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Conclusion <a class=\"anchor\" id=\"Conclusion\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The hyperparameters chosen for each model and each classification metrics are shown in the dataframe at the end of the notebook. As we can see the setting of the hyperparameter highly relies on the choice of classiffication metrics, and therefore this last should be chosen with care. Note also that the tuning of our hyperparameter was really coarse and should be refined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.system('jupyter nbconvert --to html ExecutiveSummaryPS2.ipynb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
